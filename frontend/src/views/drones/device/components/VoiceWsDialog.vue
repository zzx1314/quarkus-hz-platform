<template>
  <el-dialog
    v-model="visible"
    title="ğŸ™ï¸ è¯­éŸ³è¯†åˆ«"
    width="520px"
    :close-on-click-modal="false"
    @close="handleClose"
  >
    <div class="content">
      <div class="buttons">
        <el-button type="primary" :disabled="recording" @click="startRecording">
          å¼€å§‹å½•éŸ³
        </el-button>

        <el-button type="danger" :disabled="!recording" @click="stopRecording">
          åœæ­¢å¹¶å‘é€
        </el-button>
      </div>

      <div class="status">
        çŠ¶æ€ï¼š<strong>{{ status }}</strong>
      </div>

      <el-input
        v-model="result"
        type="textarea"
        :rows="5"
        placeholder="è¯†åˆ«ç»“æœå°†åœ¨è¿™é‡Œæ˜¾ç¤º"
        readonly
      />
    </div>

    <template #footer>
      <el-button @click="visible = false">å…³é—­</el-button>
    </template>
  </el-dialog>
</template>

<script setup>
import { ref } from "vue";

const recording = ref(false);
const status = ref("æœªå¼€å§‹");
const result = ref("");

const SERVER_IP = "192.168.41.227";
const SERVER_PORT = 8000;
const WS_URL = `ws://${SERVER_IP}:${SERVER_PORT}/ws`;
const TARGET_SAMPLE_RATE = 16000;

let audioContext;
let mediaStream;
let sourceNode;
let workletNode;
let ws;
let audioChunks = [];

const startRecording = async () => {
  result.value = "";
  audioChunks = [];
  status.value = "è¿æ¥æœåŠ¡å™¨...";

  ws = new WebSocket(WS_URL);
  ws.binaryType = "arraybuffer";

  ws.onopen = async () => {
    status.value = "å½•éŸ³ä¸­...";
    recording.value = true;

    audioContext = new AudioContext({ sampleRate: TARGET_SAMPLE_RATE });

    // åŠ è½½ worklet
    await audioContext.audioWorklet.addModule("/audio-processor.js");

    mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true });
    sourceNode = audioContext.createMediaStreamSource(mediaStream);

    workletNode = new AudioWorkletNode(audioContext, "audio-processor");

    workletNode.port.onmessage = e => {
      audioChunks.push(e.data);
    };

    sourceNode.connect(workletNode);
    workletNode.connect(audioContext.destination);
  };
};

const stopRecording = () => {
  recording.value = false;
  status.value = "å‘é€éŸ³é¢‘ä¸­...";

  sourceNode?.disconnect();
  workletNode?.disconnect();
  mediaStream?.getTracks().forEach(t => t.stop());

  const totalLength = audioChunks.reduce((s, a) => s + a.length, 0);
  const audioData = new Float32Array(totalLength);

  let offset = 0;
  for (const chunk of audioChunks) {
    audioData.set(chunk, offset);
    offset += chunk.length;
  }

  ws.send(audioData.buffer);
  ws.send("EOF");

  ws.onmessage = e => {
    result.value = JSON.parse(e.data).text;
    status.value = "è¯†åˆ«å®Œæˆ";
  };
};
</script>
